<!DOCTYPE html><html lang="zh-CN"><head><meta name="google-site-verification" content="YCdLZ428Qxbc1A-LthSxDRD0i9qhYVAMj6s4vMllnOs"><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="Hexo Theme Keep"><meta name="description" content="Hexo Theme Keep"><meta name="author" content="RevoSpeech"><title>语音合成 | 论文笔记 | VALL-E | RevoSpeech</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230228/favicon_white.jpg"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/fontawesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/regular.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/solid.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/brands.min.css"><script id="hexo-configurations">let KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"revospeech.github.io",root:"/",language:"zh-CN",path:"search.json"},KEEP.theme_config={toc:{enable:!0,number:!0,expand_all:!0,init_open:!0},style:{primary_color:"#0066cc",logo:"https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230211/R-scale.jpg",favicon:"https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230228/favicon_white.jpg",avatar:"https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230211/avatar.mn776y46kc0.jpg",font_size:null,font_family:null,hover:{shadow:!0,scale:!0},first_screen:{enable:!0,header_transparent:!1,background_img:"https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230212/background-mask-grey.jpg",description:"Revive and Evolve || Towards the Future",font_color:"#E9E9E9",hitokoto:!1},scroll:{progress_bar:!0,percent:!0}},local_search:{enable:!0,preload:!0},code_copy:{},code_block:{tools:{enable:!0,style:"default"},highlight_theme:"obsidian"},side_tools:{},pjax:{enable:!0},lazyload:{enable:!0},comment:{enable:!1,use:"waline",valine:{appid:null,appkey:null,server_urls:null,placeholder:null},gitalk:{github_id:null,github_admins:null,repository:null,client_id:null,client_secret:null,proxy:null},twikoo:{env_id:null,region:null,version:"1.6.8"},waline:{server_url:"https://ixvtasha.api.lncldglobal.com",reaction:!1,version:2}},post:{author_label:{enable:!0,auto:!0,custom_label_list:["Trainee","Engineer","Architect"]},word_count:{enable:!0,wordcount:!0,min2read:!0},img_align:"center",copyright_info:!0},version:"3.6.1"},KEEP.language_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"},KEEP.language_code_block={copy:"复制代码",copied:"已复制",fold:"折叠代码块",folded:"已折叠"},KEEP.language_copy_copyright={copy:"复制版权信息",copied:"已复制",title:"原文标题",author:"原文作者",link:"原文链接"}</script><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="RevoSpeech" type="application/atom+xml">
</head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span> <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="header-wrapper"><div class="header-content"><div class="left"><a class="logo-image" href="/"><img src="https://cdn.staticaly.com/gh/revospeech/image-hosting@master/20230211/R-scale.jpg"> </a><a class="logo-title" href="/">RevoSpeech</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/">首页</a></li><li class="menu-item"><a href="/archives">归档</a></li><li class="menu-item"><a href="/tags">标签</a></li><li class="menu-item"><a href="/about">关于</a></li><li class="menu-item search search-popup-trigger"><i class="fas fa-search"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/">首页</a></li><li class="drawer-menu-item flex-center"><a href="/archives">归档</a></li><li class="drawer-menu-item flex-center"><a href="/tags">标签</a></li><li class="drawer-menu-item flex-center"><a href="/about">关于</a></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="page-template-container"><div class="page-template-content keep-markdown-body"><p>之前介绍了 <strong>AudioLM</strong> 和 <strong>MusicLM</strong> 两篇基于 <strong>SoundStream</strong> 的音频/音乐生成的论文，思想都是：将音频编解码的 SoundStream 模型作为音频信号离散化的 tokenizer，在量化后的声学 token 上进行语言模型建模，最大程度地保留了音频生成所需的细节信息，这也成为了一种行之有效的音频生成方法论。本篇介绍的论文 VALL-E 将这一思想应用于语音合成任务（之前的 AudioLM 也可以做语音的续写生成，但不是以文本为条件（Condition）的 Text-to-Speech 的语音合成），使用更优的 <strong>Encodec</strong> 音频编解码器，实现了一种有效的 zero-shot TTS 模型。</p><br><table><thead><tr><th align="center">会议/期刊</th><th align="center">年份</th><th align="center">题目</th><th align="center">链接</th></tr></thead><tbody><tr><td align="center">arxiv</td><td align="center">2023</td><td align="center">Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</td><td align="center"><a class="link" target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.02111">https://arxiv.org/abs/2301.02111<i class="fas fa-external-link-alt"></i></a></td></tr></tbody></table><br><p>VALL-E 将语音合成视为一种<strong>条件语言建模</strong>（Conditional Language Modeling）的任务，使用神经网络音频编解码器的中间结果作为音频的离散表征，在此表征的基础上进行语言建模。VALL-E 使用 6 万小时量级的英语语音数据（语音合成的数据量也卷起来了）进行预训练，在对未见过的目标说话人进行 zero-shot 推理时，只需要 3 秒的音频作为 <strong>prompt</strong>（也可称为前缀），即可实现高自然度 + 高音色相似度的语音合成，在语音的情感、声学环境等方面也能和 prompt 的语音保持一致，体现出 VALL-E 已经具备 <strong>in-context learning</strong> 的能力。</p><h3 id="论文背景与概述"><a href="#论文背景与概述" class="headerlink" title="论文背景与概述"></a>论文背景与概述</h3><p>语音合成的训练数据通常对音频质量要求较高，网络上的语音数据虽然很多，但是绝大多数质量较低、不够干净，无法用来训练语音合成模型；同时，高质量音频的稀缺，也导致目前的语音合成系统通常泛化性较差，对于训练数据中没有出现过的说话人（zero-shot），语音合成的音色相似度和自然度都显著降低。</p><p>针对 zero-shot TTS 问题，目前的工作大多采用 Speaker / Style Encoder 等<strong>基于参考音频</strong>的方法，从参考音频中提取全局的说话人特性信息，并显式注入到 TTS 模型中。VALL-E 则完全跳脱出了这种思想，只需要从 prompt 语音抽取离散化的声学 token，基于声学 token 和输入的音素序列，使用条件语言模型对后续的声学 token 进行预测，然后从声学 token 解码恢复出语音波形。</p><blockquote><p>NLP 文本生成任务中大语言模型的启发：一方面，更大的<strong>数据量</strong>可以显著提高模型的泛化性；另一方面，<strong>语言模型</strong>相比于 VAE / GAN / Diffusion 等生成式模型，可能是一种更简单有效的生成模型。NLP 领域近几年涌现了很多值得借鉴的大语言模型（<strong>LLMs</strong>，Large Language Models）工作（比如 GPT 系列），之后在其他文章中会另做梳理。</p></blockquote><p>VALL-E 工作的贡献可以概括为：</p><ol><li>VALL-E 使用音频编解码器中的编码结果而不是梅尔特征作为 TTS 系统建模时的中间表征，并采用条件语言模型的建模方法，具有上下文学习（In-Context Learning）的能力，推理阶段可以使用目标说话人语音作为 prompt 直接实现 zero-shot 语音合成，不需要对模型进行 finetune；</li><li>VALL-E 使用了大量的数据，采用的是半监督的方式：一部分有标注语音训练 ASR 模型，然后对大量的无标注语音进行识别得到伪标签，用于模型的训练；</li><li>对于同样的文本输入，VALL-E 能够根据 prompt 的不同而生成不同说话人、不同情感、不同录音环境的多样的语音；</li><li>VALL-E 在 zero-shot 场景下合成的语音具有 SOTA 的音色相似度和自然度。</li></ol><p>持续更新…</p></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info info-item">&copy; <span>2023</span> - 2023 &nbsp;<i class="fas fa-heart icon-animate"></i> &nbsp;<a href="/">RevoSpeech</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item">总字数&nbsp;25.4k 总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></div><div class="theme-info info-item">由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a></div></div></footer></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="side-tools-list"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item tool-dark-light-toggle flex-center"><i class="fas fa-moon"></i></li><li class="tools-item rss flex-center"><a class="flex-center" href="/atom.xml" target="_blank"><i class="fas fa-rss"></i></a></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list"><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li><li class="tools-item tool-scroll-to-top flex-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="zoom-in-image-mask"><img class="zoom-in-image"></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="close-popup-btn"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/dark-light-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/code-block.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/lazyload.js"></script><div class="post-scripts pjax"></div><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{KEEP.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{KEEP.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),KEEP.refresh()})})</script></body></html>